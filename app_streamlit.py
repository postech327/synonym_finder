import streamlit as st
from openai import OpenAI  # âœ… ìµœì‹  SDK
import os
import json
import pandas as pd
from dotenv import load_dotenv
from prompts import make_prompt
from utils import parse_table
from docx import Document  # Word ì €ì¥ìš©
from datetime import datetime  # íŒŒì¼ëª… ìë™í™”ìš©
from gtts import gTTS  # âœ… ìŒì„± ì €ì¥ìš© (gTTSëŠ” ì˜ì–´/í•œêµ­ì–´ ì§€ì›)

# .envì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  # âœ… ìµœì‹  ë°©ì‹

SAVE_FILE = "saved_words.json"
RESULT_FILE = "saved_results.json"

# ğŸ”¹ ì €ì¥ëœ ë‹¨ì–´ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
def load_saved_words():
    if os.path.exists(SAVE_FILE):
        with open(SAVE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

# ğŸ”¹ ìœ ì˜ì–´ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
def load_saved_results():
    if os.path.exists(RESULT_FILE):
        with open(RESULT_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

# ğŸ”¹ ë‹¨ì–´ ì €ì¥
def save_user_word(username, word):
    data = load_saved_words()
    if username not in data:
        data[username] = []
    if word not in data[username]:
        data[username].append(word)
        with open(SAVE_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

# ğŸ”¹ ìœ ì˜ì–´ ê²°ê³¼ ì €ì¥
def save_user_results(username, result):
    data = load_saved_results()
    if username not in data:
        data[username] = []
    data[username].extend(result)
    with open(RESULT_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ğŸ”¹ ë‹¨ì–´ ë¶ˆëŸ¬ì˜¤ê¸°
def get_user_words(username):
    data = load_saved_words()
    return data.get(username, [])

# ğŸ”¹ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
def get_user_results(username):
    data = load_saved_results()
    return data.get(username, [])

# ğŸ”¹ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
def make_analysis_prompt(text):
    return f"""
This GPT has two main functions: flow analysis and question generation, both based on a given passage. Users provide a text passage, and the GPT will analyze its flow and generate relevant multiple-choice questions in English and Korean. All summaries provided will be concise and in Korean, limited to less than 20 characters.

**Flow Analysis (in Korean)**
1. The passage is broken down into three sectionsâ€”Introduction, Body, and Conclusion.
2. For each section, the GPT will:
  - **Subject Matter**: Identify and describe the main focus of the section in Korean.
  - **Summary**: Provide a brief summary in Korean, ensuring it is less than 20 characters.

**Question Generation (Both in English and Korean)**
1. **Multiple-Choice Questions**: Create relevant questions with 5 answer choices. Each question will have:
  - **Title**: A question to determine the best title for the passage, using styles and examples based on those in the attached reference PDF. Ensure options are of varying sentence lengths and meanings for clarity and distinction.
  - **Topic**: A question to determine the best topic for the passage, following similar guidelines as the title question. On Topic, choices should be given in small letters.
  - **Main Idea**: A question to determine the best main idea for the passage, with 5 choices listed by sentence length. The correct answer will be distinct, and the wrong answers will differ in content and context to avoid overlapping meaning with the correct one.
  - **Summary**: Summarize the passage in one sentence.

Each question will be provided with one correct answer, and the answers will be translated into Korean. The wrong answers should be translated into Korean as well. Make the choices in circled digits like â‘  â‘¡ â‘¢ â‘£ â‘¤. English and Korean choices should be given separately. To ensure variety, the correct answer should not always be option â‘ , but instead randomly assigned among the five options for each question.
ğŸ“Œ You **must provide the correct answer explicitly** for each question in both English and Korean.
Passage:
{text}
    """

# ğŸ”¹ ë¶ˆì¼ì¹˜ ë¬¸ì œìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
def make_false_statements_prompt(text):
    return f"""
This GPT generates multiple-choice questions (MCQs) in both English and Korean based on a given passage. It follows a structured format where:

1. A passage is provided by the user.
2. A question is created asking the user to select all choices that do not match the passage.
3. Answer choices are labeled with â“ â“‘ â“’ â““ â“” â“• â“– â“—.
4. The wording of answer choices is varied to avoid direct repetition of the passage.
5. Just three incorrect choices are included.(They are the answers: only three)
6. Correct answers are provided with detailed explanations.
7. The entire question, choices, answers, and explanations are provided in both **English and Korean**.
8. English and Korean should be separated.

This GPT is ideal for language learners, educators, and test creators who need bilingual comprehension questions. It ensures accuracy and consistency while maintaining clarity in both languages.

    Passage:
    {text}
"""

# ğŸ”¹ ë¹ˆì¹¸ ë¬¸ì œìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
def make_blank_question_prompt(text):
    return f"""
This GPT generates multiple-choice questions (MCQs) in both English and Korean based on a given passage. It follows a structured format where: 

1. A passage is provided by the user.
2. A question is created by turning the topic sentence or key idea of the passage into a fill-in-the-blank format.
3. Answer choices are labeled with â‘  â‘¡ â‘¢ â‘£ â‘¤. 
4. The correct answer must match the original sentence from the passage exactly, while the incorrect choices are created by modifying the correct answer to express opposite or irrelevant ideas.
5. The entire question, choices, and answers are provided in both **English and Korean**. 
6. English and Korean should be separated.

Passage:
{text}
"""

# ğŸ”¹ Word ì €ì¥ í•¨ìˆ˜
def save_to_word_file(content, filename=None):
    doc = Document()
    doc.add_heading("GPT ë¬¸ì œ ìƒì„± ê²°ê³¼", level=1)
    for line in content.split("\n"):
        doc.add_paragraph(line)
    if not filename:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"gpt_questions_{timestamp}.docx"
    doc.save(filename)
    return filename

# ğŸ”¹ MP3 ì €ì¥ í•¨ìˆ˜ (gTTS ì´ìš©)
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ§ í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜")
custom_voice_input = st.sidebar.text_area("ğŸ“œ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
voice_lang = st.sidebar.radio("ğŸŒ ìŒì„± ì–¸ì–´ ì„ íƒ", ["í•œêµ­ì–´", "ì˜ì–´"], horizontal=True)

if st.sidebar.button("ğŸ”Š ìŒì„± ì €ì¥ (mp3)"):
    if not custom_voice_input.strip():
        st.sidebar.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"tts_output_{timestamp}.mp3"

        lang_code = "ko" if voice_lang == "í•œêµ­ì–´" else "en"
        tts = gTTS(text=custom_voice_input, lang=lang_code)
        tts.save(filename)

        with open(filename, "rb") as f:
            st.sidebar.download_button(
                label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ: ìŒì„± íŒŒì¼",
                data=f,
                file_name=filename,
                mime="audio/mpeg"
            )

# ğŸ”¹ Streamlit UI ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ“˜ GPT ê¸°ë°˜ ì˜ì–´ ë¬¸ì œ ìƒì„±ê¸°")

menu = st.sidebar.radio("ê¸°ëŠ¥ ì„ íƒ", ["ì£¼ì œÂ·ì œëª©Â·ìš”ì§€", "ë¶ˆì¼ì¹˜ ë¬¸ì œ", "ë¹ˆì¹¸ ë¬¸ì œ", "ì „ì²´ ë¬¸ì œ ìƒì„±"])
input_text = st.text_area("âœï¸ ì§€ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", height=300)

if st.button("ğŸ¯ ë¬¸ì œ ìƒì„±"):
    if not input_text.strip():
        st.warning("ì§€ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        prompts = {
            "ì£¼ì œÂ·ì œëª©Â·ìš”ì§€": make_analysis_prompt(input_text),
            "ë¶ˆì¼ì¹˜ ë¬¸ì œ": make_false_statements_prompt(input_text),
            "ë¹ˆì¹¸ ë¬¸ì œ": make_blank_question_prompt(input_text),
        }
        if menu == "ì „ì²´ ë¬¸ì œ ìƒì„±":
            combined_result = ""
            with st.spinner("GPTë¡œë¶€í„° ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘..."):
                for title, prompt in prompts.items():
                    response = client.chat.completions.create(
                        model="gpt-4",
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.7
                    )
                    content = response.choices[0].message.content
                    combined_result += f"ğŸ”· {title} ê²°ê³¼\n\n{content}\n\n{'='*80}\n\n"
            st.session_state.generated_content = combined_result
            st.success("âœ… ì „ì²´ ë¬¸ì œ ìƒì„± ì™„ë£Œ!")
            st.text_area("ğŸ§¾ ì „ì²´ ê²°ê³¼", value=combined_result, height=500)
        else:
            prompt = prompts[menu]
            with st.spinner("GPTë¡œë¶€í„° ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘..."):
                response = client.chat.completions.create(
                    model="gpt-4",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7
                )
                content = response.choices[0].message.content
                st.session_state.generated_content = content
                st.success("âœ… ìƒì„± ì™„ë£Œ!")
                st.text_area("ğŸ§¾ ìƒì„±ëœ ê²°ê³¼", value=content, height=400)

# ğŸ”¹ ì €ì¥ ë²„íŠ¼
if 'generated_content' in st.session_state and st.session_state.generated_content:
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ“„ Wordë¡œ ì €ì¥"):
            filename = save_to_word_file(st.session_state.generated_content)
            with open(filename, "rb") as f:
                st.download_button(
                    label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ: Word íŒŒì¼",
                    data=f,
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
    with col2:
        if st.button("ğŸ”Š ìŒì„±(mp3)ìœ¼ë¡œ ì €ì¥"):
            filename = save_to_mp3(st.session_state.generated_content)
            with open(filename, "rb") as f:
                st.download_button(
                    label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ: ìŒì„± íŒŒì¼",
                    data=f,
                    file_name=filename,
                    mime="audio/mpeg"
                )
